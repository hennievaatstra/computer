vid.01 Setup the environment for this video

vid.02 Ansible inventory & configfile
  - ansible.cfg:
    [defaults]
      remote_user,inventory,roles_path.collections_path,ask_pass=false
    HV:
      - separate muliple paths with :
      - for collections maybe also set ~/.ansible/collections and /usr/share/ansible/collections
    [privilege_escalation]
      become,become_user,become_method,become_ask_pass
  - inventory:
      [dev],[test],[prod],[balancers],[webservers:children]
  - check:
      $ ansible --version
      $ ansible all --list-hosts
      $ ansible all -m ping

vid.03 Configuration of local YUM repo
  - maak playbook met 2 tasks
    - task 1 AppStream
      gpgcheck: http://content.....
    - task 2 BaseOS
      gpgcheck: http://content.....
  - run playbook
      $ ansible-navigator run -m stdout <playbook>
  - check:
      $ ansible all -m command -a "ls /etc/yum.repos.d"
      $ ansible all -m command -a "yum clean all"
      $ ansible all -m command -a "yum repolist all"

vid.04 Installation of collections
  !! gebruik full-pathnames met galaxy "just to be sure"
  $ ansible-galaxy collection install <URL> -p /home/student/ansible/collections/
  - check:
      $ ansible-navigator collections
  - check [for ansible.posix present]
      $ ansible-navigator doc -m stdout firewalld

vid.05. Installation of roles
- install 2 roles: balancer en phpinfo
  !! hij doet phpinfo eerst, dan balancer
  - requirements.yml:
    - src: http://github.com/.......git
      name: phpinfo
    - src: http://github.com/.......git
      name: balancer
  - install:
    $ ansible-galaxy install -r /home/student/ansible/roles/requirements.yml -p /home/student/ansible/roles/
  !! gebruik full-pathnames met galaxy
  HV: for requirements.yml see 'Galaxy User Guide' at docs.ansible.com
    - -r option to specify a requirements.file
    - syntax in course is:
      - name:
        src:
	scm:
	version:

vid.06. Create offline role
  $ cd roles/
    $ ansible-galaxy init <rolename>
  - in template:
    My host is {{ ansible_facts['hostname'] }} on {{ ansible_facts['default_ipv4']['address'] }}
  - playbook to import role:
    - host: dev
      roles:
        - apache
  - check:
    $ ansible-navigator run -m stdout --syntax-check
    $ ansible-navigator run -m stdout
  - check webserver running:
    $ curl http://node1.lab.example.com
    My host is node1 on 192.168.1.10

vid.07 Install roles
  - create playbook to import roles
    $ vi <playbook>
    - hosts: webservers
      roles:
        - phpinfo
    - hosts: balancers
      roles:
        - balancers
  - run balancer and phpinfo roles
   $ ansible-navigator run -m stdout <playbook> 
   ! copy the selinux system to ./roles
   ! rocky9: add community.general collection:
   $ ansible-galaxy collection install community.general
   ! and selinux related rpms:
   $ sudo dnf install python3-libselinux python3-policycoreutils

vid.08 Installation of RHEL system roles
  - you get either timesync or SELinux
  - install systemroles RPM (!)
    $ sudo dnf install rhel-system-roles -y
  - check:
    $ ls /usr/share/ansible/roles
  !! he copies ~/ansible/collections/rhel-system-roles.timesync to ~/ansible/roles
  - create timesync playbook
    - hosts:
      vars:
        timesync_ntp_servers:
          - hostname: <IP>
            iburst: yes
      roles:
        - rhel-system-roles.timesync
  !! see README.md in role
  !! vars may also be specified under group_vars/<group>/<file>.yml
  - run
    $ ansible-navigator run -m stdout <playbook.yml>

vid.09 Install of SELinux systemroles
  - see vid.08
  - install systemroles RPM
    $ sudo dnf install rhel-system-roles -y
  - again: copy from collections/ to roles/
  - create selinux playbook
    - hosts: all
      vars:
        selinux_state: enforcing
        selinux_policy: targeted
      roles:
        - rhel-system-roles.selinux 
  !! see README.md in role
  - run
    $ ansible-navigator run -m stdout <playbook>
  - check
    $ ansible all -m command "cat /etc/selinux/config"

vid.10 Creation of web content
  !! check eerst of firewalld/httpd installed/running on target hosts
     - install/enable if needed
  - create playbook
  - use modules:
    file: copy: firewalld: [service: ?]

vid.11 Installation of packages
  - php and mariadb on dev,test,prod
  - 'Development tools' group on dev
    !! use quotes around group name
  - update all packages on dev
  !! he does it with 2 plays
    - one play for dev,test,prod
    - second for dev  

 vic.12 Collection of hwreport
  - download hwreport.txt from url to /root
    - fill in the key=value lines with real values
    - if no information it should show "NONE"
  - first check info
    $ ansible all -a "lsblk"
      - for disk names
    $ ansible <node> -m setup
      - for all variables 
  !! he uses a block: rescue: playbook
     - set ignore_errors: true on play level
     - and first downloads the hwreport.txt to control node to use as template
     - then get_url: to put file on target host
     - then template: to fill in values
     - next rescue: if first two fail use template 2
  ?? can't it be done with lineinfile: for each line ??
  - template 1:
      HOSTNAME={{ ansible_hostname }}
      MEMORY={{ ansible_memtotal_mb }}
      BIOS={{ ansible_bios_version }}
      CPU={{ ansible_processor }}
      DISK_SIZE_VDA={{ ansible_facts['devices']['vda']['size'] | default('NONE')  }}
      DISK_SIZE_VDB={{ ansible_facts['devices']['vdb']['size'] | default('NONE')  }}
  - template 2: is the same except for:
      DISK_SIZE_VDB=NONE

vid.13 Replacing the contents
  - replace content in /etc/issue
  - copy: module
      content:
      dest:
  - use when: clause
    when: inventory_hostname in groups['dev']
  - check:
    $ ansible dev,test,prod -a "cat /etc/issue"

vid.14 Collection of nodes info
  - download file from URL
    - to control node
  - use it as template to create an /etc/hosts like file /etc/myhosts
  - since several lines of all nodes need to be entered, use a loop in jinja2 template
  - loop:
    {% for myhost in groups['all'] %}
    {{ hostvars[myhost].ansible_default_ipv4.address }} {{ hostvars[myhost].ansible_fqdn }} {{ hostvars[myhost].ansible_hostname }}
    {% endfor %}
  - run
  - check:
    $ ansible all -m command "cat /etc/myhosts"

vid.15 Creation of a vault file
  - create an ansible vault file
    $ ansible-vault create lock.yml
  - contains a variable an its value
    pwdeveloper: Iamdev
    pwmanager: Iammgr
  - store passwd 'P@ssword' of vault file in secret.txt
    echo 'P@assword' > secret.txt

vid.16 Create user and groups
  - download variable file to control node
  - play for group opsdev
    - create group
    - create user when job is developer
    - assign passwd {{ pwdeveloper }} with SHA512
      passwd: "{{ pwdeveloper | password_hash('sah512') }}
  - play for group opsmgr
    - create group
    - create user when job is manager
    - assign passwd {{ pwmanager }} with SHA512
  - use vars_files: to add in user_list.yml and vault.yml
  - use loop: to iterate over the myusers dict in user_list.yml
    loop: {{ myusers }}
    use {{ item.user }} for the username
  - HE also uses passsword_expire_max: "{{ item.password_expire_days }}"
  - use when: condition for each play
    when: item.job == "developer"
  !! to run use extra options to disable playbookartifacts and specify secret for vault
     --pae false
     --vault-password-file=secret.txt
  $ ansible-navigator -m stdout run <playbook> --pae false --vault-password-file=<secretfile>
  - check:
  $ ansible dev,test -m command -a "tail /etc/group"

vid.17 Resetting the vault passwd
  - download vaulted file
  - rekey
    $ ansible-vault rekey <file>
  - check:
    $ ansible vault view <file>
    use new password

vid.18 Creating a cron job
  - use cron: module
  - read carefully and use correct options
    - see ansible-doc cron
  - check:
    $ ansible all -m command -a "ls /var/spool/cron"
    $ ansible all -a crontab -a "crontab -lu <username>"

vid.19 Creating a Logical Volume
  - create LV of 1500MB in vg research
       lvol:
       when: ansible_lvm.vgs.research.size_g > "1500 MiB"
    - verify if vg not exists
      - then write error message
       debug:
       when: ansible_lvm.vgs.research.size_g < "1500 MiB"
    - if no 1500MB free then write error
  - format 1500m LV as ext4
  - NO mounting
  > check first
    $ ansible all -m command "vgs"
    $ ansible all -m command "lvs"
    $ ansible all -m command "lsblk"
  - HIS structure:
    block:
      block:
        lvol: 1500
        when: vg research > 1500
      block:
        debug: insufficient space
        lvol: 800
        when: vg research < 1500
    when: ansible_lvm.vg.research is defined

    name: format the LV
    filesystem: 

    name: no vg.research
    debug:
