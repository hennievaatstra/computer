Chapter 1 Developing Playbooks with Ansible Automation Platform 2

AAP2 components:
- Ansible Core
  - fundamental functionality used to run Ansible Playbooks
  - defines automation language used to write playbooks in yaml
  - provides key functions [loops,conditionals etc]
  - provides framework and basic command-line tools
  - provides in ansible-core rpm
- Ansible Content Collections
  - previously modules
  - now reorganizes into separate collections
  - made up of related modules, roles and plugins
  - ansible core is limited to a small set of modules 'ansible.builtin'
  - ansible.builtin is always available
  - collections provide flexibility to:
    - select different versions of collections
    - or different sets of collections
    - ability to update modules on a separate cadence from Ansible itself
- Ansible Content Navigator
  - new top-level tool to develop and test Ansible playbooks
  - replaces and extends earlier command-line utilities, including:
    - ansible-playbook
    - ansible-inventory
    - ansible-config
  - separates the control node [on which you run Ansible] from the automation execution environment that runs is
  - by running the playbooks in a container
- Automation Execution Environments
  - conainer images that contain AnsibleCore, AnsibleContentCollections
  - and any Python libraries, executables or other dependencies needed to run playbooks
  - default environment in AAP 2.2 provides AnsibleCore 2.13
  - and collections to provide a user experience similar to Ansible 2.9
  - you an use ansible-builder to create you own execution environments
- Automation Controller
  - formerly called Ansible Tower
  - provides central point of control to run enterprise automation code
  - in Tower, the system was both control node and execution environment
  - now separated
  - can run execution environments on remote nodes
  - communicating over the network using a feature calles automation-mesh
- Automation Hub
  - provides a way to manage and distribute automation content
  - a public service at console.redat.com provides access to Red Hat Ansible Certified Content Collections
  - that can be downloaded and used with ansible-galaxy and with automation controller
  - you can also setup a private automation hub for your own AnsibleContentCollections
Hosted services
  - addition to the hosted automation at console.redhat.com
  - Red Hat Insights for RedHat AAP
    - helps you understand what automation code you are running and whether it is successful
    - also to evaluate the positive impact on you organization
  - Automation Analytics
    - helps to provide better insight into the performance of you automation infrastructure
    - to analyze how you use automation and what modules/playbooks/workflows yuou most frequently use

QUIZ
1c 2a 3d 4a 5b

Running Playbooks with Automation Content Navigator

ansible-navigator
 - new tool in AAP2
 - combines features formerly provided by: ansible-[playbook|inventory|config|doc]
 - new interactive mode woith text-based interface
 - can be run using "--mode stdout" to provide output like the previous tools
 eg:
 old: $ ansible-playbook playbook.yml -i inventory
 new: $ ansible-navigator run playbook.yml -i inventory -m stdout

automation execution environment
- a container image that includes Ansible Content Collections
- their software dependencies
- and a minimal Ansible engine
- use by both ansible-navigator and automation controller
- helps to avoid creating multiple Python virtual environments
- when no exec.env is specified, the default is pulled from registry.redhat.com
- this needs to authenticate
- you need a login to registry.redhat.com and a valid subscription to AAP
- use: podman login registry.redhat.io before running ansible-navigator
- required only once per session
- use --execution-environmnet-image (-eei) to select a specific container
- eg.: ee-supported-rhel8:latest to use the latest [tagged] version of that image

Install Automation Content Navigator
- ansible-navigator is only installed on your control node
- you need a valid AAP subscription
- installation procedure:
  - Register using RHSM:
  $ subscription-manager register
  - Enable AAP2 repo:
  $ subscription-manager repos --enable ansible-automation-platform-2.2-for-rhel-8-x86_64-rpms
  - install ansible-navigator
  $ yum install ansible-navigator

Configuring Authentication to Managed Hosts
- automation content navigator need login to managed hosts and superuser access
- easiest way by SSH key-based authentication
- to an account that allows privilege escalation through sudo without password

Preparing SSH Key-based authentication
- set a remote_user directive in de [defaults] section of ansible config on control node
- use ssh-keygen to generate SSH key pair for user that runs ansible-navigator
- install its public key in ~/.ssh/authorized_keys file for the remote_user on each managed hsots
- on managed hosts configure passwordless sudo for the remote_user
! ansible-navigator runs in a container and cannot access your ~/.ssh directory
- running ssh-agent on controlnode can provide SSH private keys to execution environment
- GUI login autoprovides ssh-agent and ssh-add us run to add private keys
- ssh login must start ssh-agent [eval $(ssh-agent)], then run ssh-add, then run ansible-navigator in the same shell

Running Automation Content Navigator
- $ ansible-navigator
- old vs new:
- ansible-[config|doc|inventory|playbook]
- ansible-navigator [config|doc|inventory|run]
- subcommands: [collections|config|doc|help|images|inventory|log|open|replay|run]
- in interactive session run eg. :config  to start the subcommand
- run playbook:
  - commandline: ansible-navigator run ...
  - interactive: ansible-navigator :run
- review previous playbook run
  - per default 'playbook artifacts' are enabled
  - names as: site-artifact-2022-10-25T20_05_7.939910+10:00.json
  - can most often be safely ignored/removed
- ansible-navigator doc does NOT support option --list (-l)
- you must explicitly sepcifiy the plug-in name

Guided Excercise
Running Playbooks with Automation Content Navigator
1. install ansible-navigator
  $ sudo yum install ansible-navigator
2. review the excercise playbook
  $ less intranet.yml
3. run the playbook using navigator
  $ podman login hub.lab.example.com
  username; student
  Password: redhat123
  $ ansible-navigator run intranet.yml -m stdout --eei ee-supported-rhel8
4. run the playbook interactively
  $ ansible-navigator --eei ee-supported-rhel8
  :run intranet.yml
  0 - to display details
  ESC - to return to main playbook summary page
  :q - to quit navigator

Implementing Receommended Ansible Practices
- Jeff Geerling:
  - keep things simple
  - stay organized
  - test often
- Keep things simple:
  - use native YAML syntax [indented, multilines]
  - not the "folded" syntax [much on single line]
  - use existing modules
  - adhere to a standard style
    - how many spaces to indent
    - how many vertical white space
    - naming of tasks, plays, roles, variables
    - commenting
- Stay organized
  - take advantage of Ansible organization features
  - such as roles
  - follow conventions for naming
    - use descriptive variables, suc as apache_tls_port
    - it's good practive to prefix role variables with the role name
    - variable names should clarify contents
  - standardize the project structure
  - use dynamic inventories
  - use other tools to construc groups or extra information
    - ansible.builtin.group_by generates group based on a fact
  - consider dividing hosts into different categories
    - geographical, enironmental, sites, services
  - user roles and collections for reusable content
    - use ansible-galaxy to initialize directory hierarchy
    - keer your roles in a roles subdir of your project
  - run playbooks centrally
  - ideally on an automation controller
  - build automation execution environments
    - if you need to frequently use specific Ansible Content Collections
- Perform regular testing
  - verify the result of a task
  - use block: and rescue: directives
    - block: to group tasks
    - rescue: to recover from errors or failures
  - develop playbooks with the latest Ansible version
    - to avoid issues as Ansible modules and features evolve
  - use test tools
    - ansible-navigator run <playbook> --syntax-check -m stdout
    - ansible-lint

Guided exercises:
- setup webserver on servera and serverb
- setup databasesrv on serverc and serverd
- single playbook with two plays
  - play1: webservers
  - play2: dbservers
> replace named hosts with a groupname
  - create hostgroup in inventory
> move variables to hostgroup group variable files
  - group_vars/webservers
  - group_vars/dbservers
  - change var naming in playbook accordingly
> change folded syntax to native syntax

LAB:
- clone git repo
  - $ git clone https://git.lab.example.conf/student/develop-review.git
- create new branch
  - $ git checkout -b exercise
--------------------------------------------------------------------------------

Chapter 2 Managing Content Collections and Execution Environments

Reusing Content from Ansible Content Collections
- a distribution formant for Ansible content
- sets of related modules, roles and plug-ins
- can be downloaded to controlnode
- then used in playbooks
- examples:
  - redhat.insights -  to register a system with Redhat Insights
  - cisco.ios - to manage Cisco IOS network appliances
  - community.crypto - to create SSL/TLS certificates
- install colelctions to only use content you need instead of all modules
- to select a specific version
- to choose between redhat or community versions

Organizing AnsibleContentCollections in Namespaces
- collections are organized in namespaces
- to assign unique names to collections with conflicting with others
- namespace is first part of a collection name
- namespace names are limited 
  - ASCII lowercase letter, numbers and underscore
  - two characters minimum
  - cannot start with underscore

Using Ansible Content Collections
- $ absible-navigator collections
  - to list collections available in automation execution environments
  - then type <number>: to list modules/plugins
  - then enter the module number to access its documentation

Using ACC in playbook
- refer to it with its fully qualified collection name
  - name: blah
    redhat.insights.insight_register:
- example using 'organizations' role from redhat.satellite collection:
  - name: blah
    ansible.buitling.include_role:
      name: redhat.satellite.organizations

Finding Ansible Content Collections
- to update legacy playbooks using modules that moved to collections:
- identify in which collections they are now available
- https://github.com/ansible/ansibleblob/devel/lib/ansible/config/ansible_builtin_runtime.yml to map old to new

Using the Built-in collection
- ansible.builtin always included
- set of common modules
  - copy, template, file, yum, command, service and more
- can be used with shortname
- RedHat recommends using the FQCN

Finding and Installing Ansible Content Collections
- two sources provide Asnibe Content Collections
  - automation hub : officially supported by Redhat
  - Ansible Galaxy : open source community
Automation hub
- hosts RedHat certified Ansible Content Collections
  - eg. redhat.[rhv|satellite|insights]
  - cisco.ios
- requires valid RedHat AAP subscription
- UI at https://console.redhat.com/ansible/automation-hub
Ansible Galaxy
- public site
  - eg. community.[crypt|postgresql|rabbitmq]
  - UI at https://galaxy.ansible.com

Installing Ansible Content Collections
- one method:
  - install collection in the same dir as your playbook
  - before running ansible-navigator command
  - normally you create a collecionts subdir for your collection
Install from CLI
- $ ansible-galaxy collection install community.crypto
- from local/remote .tar
  $ ansible-galaxy collection install /tmp/community-dns-1.2.0.tar.gz
- ansible checks for 'colections/' subdir in the playbookdir
- if not found: check collections_patch from ansible.cfg
- by default collections are installed in first directory that collections_paths defines
- use '-p <dir>' to psecify an alternative dir
Install with requirements file
- collections/requirements.yml
- list of collections needed for playbooks in project
- automation controller detects it
- automatically installs collections
- similar to a roles/requirements.yml file
- $ ansible-galaxy collection install -r <requirements.yml>
Listing installed collections
- $ ansible-navigator collections
- $ ansible-galaxy collection list

Configuring Collection Sources
- add additional distribution platforms in ansible.cfg
- see exmaple on .pdf page 83

Installing Collection from private Automation hub
- similar to 'automation hub'
- yo do NOT need the auth_url directives

Selecting an Execution Environment
- container image that includes:
  - Ansible Content Colletions
  - their software dependencies
  - a minimal Ansible engine to run your playbooks
- enable portable development of playbooks
- simplifies development process
- helps to ensure predictable, reproducable results
- consists of following concepts:
  - Ansible Core (or Ansible)
  - Ansilbe Content Collections
  - Python and any other dependencies
  - Ansible runner to run playbooks
- 3 prebuilt exe.envs:
 - Minimal    - ee-minimal-rhel8    - minimal with Ansible Core 2.13
 - Supported  - ee-supported-rhel8  - Core 2.13,Collections,dependencies
 - Compatibilty - ee-29-rhel8       - Ansible 2.9 based
- Minimal: good starting point
- Supported: default
- Compatibility: for Ansible 2.9 playbooks or pre-AAP2 code

Inspecting Automation Execution Environments
- $ ansible-navigator images

Using ExecEnvs with content navigator
- $ ansible-navigator run <plb.yml> -eei registry.redhat.io/ansible-automations-platform-22/ee-29-rhel8:latest
- if the container image is already on your system, you can use:
  - -eei ee-29-rhel8:latest
- if not, use 'podman login' to ensure you're authenticated to the registry
- use --pull-policy to control how images are pulled:
  - always
  - missing
  - never
  - tag [if image tag is 'latest']

Chapter 3 - Running Playbooks with Automation Controller

Introduction to Automation Controller
- previously called 'Ansible Tower'
- provdies centralized hub you can use to run your Ansible code
- provides framework for running and managing Ansible on enterprise scale
  - centralized webUI for playbook management
  - role based access control
  - centralized logging and auditing
- you can enable CI/CD by using the REST API
- provides mechanisms to enable centralized use/control of machine credentials and other secrets without exposing them to the end user

Automation Controller Architecture
- introduction of automation execution environments decouples
  - automation controller control plane
  - from its execution environment
  - was tightly coupled in Ansible Tower
- execution environments replace system executables/python/etc
- help to run automation code consistently
Tower: monolithic, poor scalability
AAP2 : decentralized/modular, scale as needed

Automation Controller Features
- Visual Dashboard
  - webUI
- RBAC
  - control access to controller objects, like
    - organizations
    - projects
    - inventories
- Graphical Inventory Management
- use webUI to create inventories
- then add hostgroups and hosts
- update inventories from an external inventory
  - cloudprovides/CMDB/GitRepo
- TaskManager and Job Scheduling 
  - schedule playbook execution
  - run routine tasks unattended
- Real-time/Historical JobStatusReporint
  - webUI displays playbook output in real-time
- User-triggerd Automation
  - users can launch job/workflow templates with single click
- Credential Management
  - controller centrally manages authentication credentials
  - encrypts password/keys provided
  - users cannot retrieve them
- Centralized Logging/Auditing
  - controller logs all playbook and remote command execution
  - can integrate logs into third-party solutions eg. Splunk/Sumologic
- Integrated Notifications
  - controller can deliver notifications to many applications
  - email,Grafana,IRC,Mattermost,Slack,Rocket.Chat,Twilio,Webhooks
- Multiplaybook Workflows
  - controller can chain together numerous playbooks
  - to facilitate implementation of complex routines
    - including provisioning,configuration,development,orchestration
- Browsable REST API
  - controller exposes every automation controller feature

Exploring Resources in Automation Controller
- Automation controller provides centralized locations for Ansible playbooks
- Several resources MUST exist before you can create a job template:
  - a machine credential to connect to managed hosts
  - a source control credential to download/sync remote content, eg. Git
  - a project that specifies location of content [such as playbooks]
  - an inventory with at least one host

Creating Credential Resources
- Ansible Galaxy/Automation Hub API Token
  - to download conten collections/roles
    - from Ansible Galaxy
    - automation hub,
    - private hub
  - after creating, you must enable the credential
    - for an organization
- Container Registry
  - to authenticate BEFORE yo ucan pull a container
    - from container registry
    - or private automation hub
- GitHub PersonalAccess Token
  - GitHub no longer supports password-based auth for https
  - to continue using https create/use GitHub personal access token
  - create a controller credentail that uses the token
- Machine
  - can use this credential to access make changes to managed hosts
  - specifies username and either password or SSH provate key
  - if needed, configure privilege exscalation
    - specify username
    - specify password
- Source Control
  - to synchronize project resources from remote repo
    - specify username and password or SSH private key
- Vault
  - use [ansible] vault credentials to decrypt from ansible vault

Chapter 4 Working with Ansible Configuration Settings

Inspecting the Ansible Configuration in Ipteractive mode
- 'ansible-navigator config' displayx current Ansible config in use by/for the 'ansible-navigator run' command
- shows source of of current ansible-navigator configuration settings
- useful for troubleshooting
- each line shows values for:
  - Name - internal name that ansible users for parameters
  - Default - whether parameter is using itd default value [True]
  - Source - when not Default, indicates here how parameter has been set
  - Current - actual value of parameter
- search sepcifi configuration parameter
  - type :filter [or :f]
- accessing parameter details
  - type the corresponding number
Inspecting local configuration
- by default ansible-navigator uses an automation exec env
- if you project does noet provide the ansible.cfg
  - ansible-navigator uses /etc/ansible/ansible.cfg from the exec env
- does NOT use the /etc/ansible/ansible.cfg from the LOCAL system
- to use that local file
  - use '--execution-environment false'
Inspecting the Ansible Configuration in Standard Output Mode
- add '--mode stdout' [or -m stdout] to the command
- in non-interactive mode subcommands are requred:
  - list - static list that describes each parameter
  - dump - lists all Ansible config params and their current values
  - view - displays contents fo ansible.cfg 

Configuring Automation Content Navigator
- create a configuration/settings file to override the default values
- useful if you want to use a different exec env and do not want to enter the correct --eei option every time ansible-navigator is run
- settings file can be JSON or YAML format
- JSON file must have extension .json
- YAML file must have extension .yml or .yaml
Locating the settings file
- Automation Content Navigator looks in following locations
  - ANSIBLE_NAVIGATOR_CONFIG env var
  - ansible-navigator.yml in current Ansible project directory
  - ~/.ansible-navigator.yml in you home directory
- each project van have its own automation content navigator settings file
- projectdirectory/homedirectory can only contain ONE settings file each
  - either a JSON or a YAML file
- ansible-navigator.yml in projectdir is stored in version control with the rest of the projects
  - overrides any configuration in het user's homedir
- ansible-navigator.yml in homedire is only used if no other config file available
- only set ANSIBLE_NAVIGATOR_CONFIG envvar to override all other configfiles

Generating a Settings File
- use 'ansible-navigator settings' to generate settings file
- to generate a sample in yml format use '--sample'
- to output config matching current effective config use '--effective'
- redirect output to save to file etc..
- --sample generates output with most lines commented [#]
  - also contains comments that describe settings
  - note: when uncommenting, ALSO remove adjacent space
- --effective generates more condensed output
  - does not contain any comments
Setting a default Execution Environment
- use the 'execution-environment' key
  - 'image' specifies the container image
    - sets the --eei option
  - 'pull' sepcifies when and how to pulle the container image
    - sets the --pp option
    - you can set additional options [eg disabling TLS]
  - 'enabled' specifies whethe to use an automation exec env or not
    - defaults to 'True'
- instead of:
  $ ansible-navigator run site.yml --eei ee-29-rhel8 --pp always
  create ansible-navigator.yml containing:
  ---
  ansible-navigator:
    execution-environment:
      image: ee-29-rhel8:latest
      pull:
        policy: always
  then run:
  $ ansible-navigator run site.yml
Setting the Default Mode to Standard Output
- add 'mode: stdout' in yml file
Disabling Playbook Artifacts
- basic design of ansible-navigator assumes you can NOT provide interactive input whil playbook is running
- navigator also records 'playbook artifact' files for each run of the playbook
  - these record information about the playbook run
  - can be used to review the results
  - review to troubleshoot issues
  - kept for compliance purposes
  - review contents with 'ansible-navigator replay <file>'
  - contents may contain sensitive information about the run
  - temporarily disable artifacts
    - ansible-navigator run --pae false
    - navigator .yml:
      playbook-artifact:
        enable: false
- by default ansible-navigator looks at registry.redhat.io of images

Chapter 5

Managing Inventories
- static inventory file
  - easy to write
  - convenient for small infrastructure
  - require manual administration
- dynamically generated inventories
  - scripts
  - dynamically determine which host/hostgroups
  - based on information from external source
    - API cloud provides
    - Cobbler
    - LDAP
    - other
  - recommended practice
    - in large environment
    - in rapid changing invironment
  - two types
    - inventory plug-ins
    - inventory scripts
Inventory plugins
- piece of python code
- generates an inventory object from a dynamic source
- Ansible ships with plug-ins for a number of external sources:
  - Amazon | Google | Azure | VMware | OpenStack | OpenShift eo.
Using inventory plugins
- prepare a configuration in YAML format
  - provides connection parameters
  - example:
  pluing: redhat.satellite.forman
  url: https://satellite.example.com
  user: ansibleinventory
  password: Sup3r53cr3t
  host_filters: 'organization="Development"'
- every inventory plug-in has documentation
  - ansible-navigator doc
  - --type / -t 
  - --list / -l
    - only plug-ins from installed Ansible Content Collections
  $ ansible-navigator doc --mode stdout --type inventory --list
  $ ansible-navigator doc --mode stdout --type inventory redhat.satellite.foreman
- to run a playbook against hosts in dynamic inventory
  - use --inventory option:
  $ ansible-navigator run --inventory ./dyn_inv.yml playbook.yml
  - if the file is executable, it is run as a script
  - otherwise it is parsed as config for inventory plugins
  - if that fails it is used as a static inventory
Developing inventory scripts
- inventory script
  - collects info from external source
  - returns inventory in JSON
  - custom program in any language
  - as long as output is JSON
  - RedHat recommends developing plugins instead of scripts
- refer to 'Inventory Scripts' in the Ansible Developer Guide
- start the script with appropriate interpreter line
  eg. #!/usr/bin/python
- make sure it is executable
- script must support '--list' and '--host <managed host>' options
- using --list , script must print JSON dictionary
Using Inventory Scripts
- just like static inventory tesxt files
- specify location
  - ansible.cfg
  - --inventory option
Managing Multiple Inventories
- ansible supports multiple inventories in the same run
- inventory location is a directory
- all inventory files in it are combined
- executable files are used to retrieve dynamic inventories
- other files as used as static inventories
  - or configuration files for inventory plugins
- inventory files should not depend on other inventory files/scripts
- currently multiple inventories are parsed in alphbetical order
  - make sure files are self-consisten
- ansible ignores files with certain suffixes
  - controlled with inventory_ignore_extensions directive
  - default= .pyc|,pyo|.swp|.bak|~|.rpm|.md|.txt|.rst|.orig|.ini|.cfg|.retry

Writing YAML inventories
- ansible uses plugins to support differen formats for inventory files
- INI format for static inventories
- plugins for dynamic inventories
- most plugins are enabled by default
- enable additional in ansible.cfg
  - enable_plugins directive
- 'script' plug-in provides support for dynamic inventory scripts
- 'ini' plug-ing provides support for INI format
- 'yaml' plugin for static inventory in YAML format
  - use blokc to organize related config items
  - indent starts new [sub] block
  - 'children' to define nested groups
  - organizes both groups and nested groups in the same place
Setting inventory variables
- use the 'vars' keyword
  - INI format:
    [monitoring]
    watcher.example.com
    [monitoring:vars]
    smtp_relay=smtp.example.com
  - YAML format:
    monitoring:
      hosts:
        watcher.example.com
      vars:
        smtp_relay: smtp.example.com
- indent variable un a host to set host variable in YAML
Converting static inventory in INI to YAML
- 'ansible-navigator inventory' designed to display entire inventory
- can be used to convert to YAML
  $ ansible-navigator inventory --mode stdout -i <ini_inv> --list --yaml
- may not be 100% complete
  - some variables are only set once for a host
Troubleshooting YAML files
- protect a colon followd by a a space
  - seen as new dictionary element
  - surround string with quotes
- protecting a variable that starts with a value
  - variable replacement performed with {{ variable }}
  - { is start of dictionary
  - enclose the placeholder with double quotes
    "{{ variable }} rest of the value"
  - in general, use double quotes for any of following reserved characters
    - {} {} > , | * & ! % # ' @
- difference between string/boolean/float
  - booleans and floating point numbers used as values for a variable must NOT be quoted
  - quoted values are treated as strings
    tempereature: 36.5  == float,numericvalue
    version: "2.0"      == string

Managing Inventory Variables
- basic principle of variables
  - to write flexible/reusable tasks/roles/playbooks
  - to specify differences in configuration between differen systems
  - set in many places:
    - defaults/main.yml and vars/main.yml for a role
    - in inventory file as host or group variable
    - in variable file group_vars/ or host_vars/ subdir of playbook/inventory
    - in a play/role/task
  - keep it simple
    - only a few different methods
    - in only a few places
  - do not repeat yourself
    - organize systems in groups
    - set common variables
  - organize variable in small readable files
    - split variable definitions in multiple files for large projects
    - group related variables in a file
    - use meaningful names
Variable Merging and Precedence
- Ansible uses precedence rules to choose a value for a variable
- from lowest precedence up:
  - commandline
    - all options on CLI have lowest precedence
      - except: --extra-vars [-e] !!
  - rolename/defaults/main.yml
  - host/group variables
    - group variables: ascending precedence
      - directly in inventory
      - for 'all' in inventory group_vars/all
      - for 'all' in playbook group_vars/all
      - for other groups in inventory group_vars/
      - for other groups in playbook group_vars/
    - host variables: ascending precedence
      - directly in inventory
      - set in inventory host_vars/
      - set in playbook host_vars/
    - host facts and cached facts
  - play variables
    - set by 'vars' section in play
    - set by prompting user with vars_prompt in a play
      - not recommended
      - nog compatible with automation-controller
    - set from external file user vars_files section of a play
      - useful for organizing large lists of variables
      - can also help to separate sensitive variables
      - that can be encrypted with Ansible Vault
    - set by a role rolename/vars/main.yml file
    - set for current block with a 'vars' section of that block
    - set for current task woth 'vars' section of that task
    - loaded dynamically with include_vars modules
    - set for host with 'set_fact' of 'register'
    - parameters set for a role when loaded by the role section
    - or by using include_role module
    - set by a 'vars' section on tasks included with include_tasks module
  - extra variables
    - set using --extra-variables or -e
    - always have highest precedence
Separating Variables from Inventory
- in large environment
  - move variable definitions into separate varaible files
  - one for each hostgroup
  - or even for each host in a hostgroup
  - use meaningful names
  project2/
    group_vars/
      db_servers/
        mysql.yml
        firewall.yml
      lb_servers/
        firewal.yml
        haproxy.yml
        ssl.yml
      web_servers/
        firewall.yml
        webapp.yml
        apache.yml

Using Special Inventory Variables
- ansible_connections
- ansible_host
- ansible_port
- ansible_user
- ansible_become_user
- ansible_python_interpreter

Configuring human readable Inventory hostnames
- by default output display the inventory hostname
- set a meaningful hostname using ansible_host:
  hosts:
    webserver_1:
      ansible_host: server100.example.com
  - will show webserver_1 in the output
  - to connect to a host by using specific IP/hostname
  - meaningful name to arbitrary named cloud systems
  - to refer to a FQDN to properly connect to it
Identify the Current host by using variables
- during playrun
- a number of variables/facts to identify current managed host
  - inventory_hostname
  - ansible_host
  - ansible_facts['hostname']
  - ansible_facts['fqdn']
- ansible_play_hosts
  - list of all hosts that have not yet failed during the current play
  - and therefor are going to be used for the tasks remaining in the play

Chapter 6

Privilege escalation strategies
- at many levels
- using directives
- or connection variables
- become | become_user | become_method | become_flags
Privilege escalation by configuration
- 'become' true in ansible.cfg; all plays use privilege escalation by default
- they use the 'become_method' to change to the 'become_user'
- if set to false in ansible.cfg,  can be overriden with -b options on CLI
  Directive         CLI
  become            --become or -b
  become_method     --become-method=
  become_user       --become-user=
  become_password   --ask-become-pass or -K
Privilege escalation in plays
- if a play does NOT specify privilege escalation, default from config/cli is used
- play overrides ansible.cfg and cli
- to ensure correct escalation, always specify in playbook
Privilege escalation in tasks
- specified in taks overrides play/config/cli
- highest precedence
Grouping with Blocks
- for subset of tasks on a play that require privilege escalation
- use become: on block: of tasks
- overrides play setting
Privilege escalation in tasks
- set inside the tasks in the role
- of set in the playbook for the role
Listing Privilege escalation with Connection Variables
- apply as inventory variables on groups or individual hosts
  Directive         ConnectionVariable
  become            ansible_become
  become_method     ansible_become_method
  become_user       ansible_become_user
  become_password   ansible_become_pass
- connection variables override become settings in config/plays/tasks/blocks/roles
Choosing Approaches
- run tasks with least privilege possible
- keep playbooks simple

Controlling the order of execution
- in a play ansible always runs tasks from roles before tasks under tasks: section
- even when roles: is lower in playbook thatn tasks:
- good practice for readability to have roles: before tasks:
Importing or Incldugin Roles as a Task
- include/import roles as a task using the roles: section of the play
  - easily run a set of tasks
  - import/include a roles
  - then run more tasks
  - might be less clear which roles a playbook uses
- use include_role: to dynamically include a role
  - 'ansible-navigator run' parses and inserts the role at the include_role: task
  - DURING execution
  - aborts the execution if errors are detected
- use import_role:  to statically import a role
  - 'ansible-navigator run' starts by parsing and inserting the role
  - BEFORE starting the execution
  - does not start execution the playbook if errors are detected
Defining Pre- and Post-tasks
- to run tasks [and their handlers] BEFORE your roles
- to run tasks AFTER normal tasks [and handlers] have run
- pre_tasks:  run BEFORE roles:
- post_tasks: run AFTER tasks: section and any handlers notified by tasks:
Order of execution [as in the example p.237:
- pre_tasks
- handlers: notified in pre_tasks [if any]
- roles:
- tasks:
- handlers: notified in roles: and tasks:
- post_tasks:
- handlers: notified in post_tasks:

- the order of these sections in the play does not change order of execution
- good practice for readability to organize the play:
  - follow order of execution
  - pre_tasks | roles | tasks | post_tasks
  - usually handlers: at the end of the play
- handers: are called after running all of the tasks
- to immediately run handlers: that haven been notified
  - use the ansible.buitlin.meta: module
  - with 'flush_handlers' parameter
- handlers: have global scope
  - a play can notify: handlers: in roles
  - on role can notify: handlers: by another role or by the play
- handlers: are run in the order they are listed
  - listed as in the handlers: section of the play
  - NOT in the order they were notified

Listening to handlers
- a handlers can also 'subscribe' to a specific nnotification
- and run when that notification is triggered
- one notification can trigger multiple handlers
- by default a handler runs when notify: matches the handler name
  - each handler must have a unique name
- to trigger multiple handlers at the same time
  - the handlers can subscribe to the same notification name
  - create a 'normal' handler
  - use 'listen: <notification>'
  - then the listen: is used by the handler instead of a call by name
- particularly helpful with roles
  - roles use notifcations to trigger handlers
  - a role can notify: a handler when an event occurs
  - other roles: play: may use this notification to run additional handlers
    - defined outside the role
Notifying Handlers
- a task can nofity multiple handlers in at least tow ways:
  - notify a list of handlers individually by name
  - notify one name for which multiple handlers are configured to listen
- if handlers are resue as a set by multiple tasks
  - easiest way to use a listen: directive
  - you can change the set of handlers included or not
  - no need to update the task:
Controlling the Order of Host Execution
- hosts: determines which hosts to manage for a play
- order is changable 
  - on a play-by-play basis
  - using order: directive
  - possible values:
    - inventory: inventory orde
    - reverse_inventory: reverse inventory order
    - sorted: sorted in alphabetical order, number before letters
    - reverse_sorted: reverse alphabetical order
    - shuffle: randomize every time the play runs
Running Selected tasks
- to run only a subset of plays/tasks in [large/complex] playbook
- apply 'tags:'
  - tag is a text label on a resource
  - specifies what to run/skip
  - tags: <list of tagnames>
  - tag an entire play: tags: in head
  - tag each task: most common, on task name level
  - tag imported_task
  - tag a role - all tasks in the role associated with the tag
  - tag a block of tasks -  all tasks in block associated with the tag
- on imported resource the tag applies to all tasks in imported role/task file
- on included resource the tag ONLY applies to that task itself
  - and ONLY runs tasks in the included role/task file that also uses the tag name
Managing tagged resources
- use ansible-navigator to run tasks with specific tags
  - --tags to run
  - --skip-tags to skip
Combining tags to run multiple tasks
- use comma separated list
  - --tags install,setup
- listing:
  - ansible-navigator run -m stdout playbook.yml -i inventory --list-tags
Assigning special tags
- 'always'
  - a resource tagged 'always' runs every time
  - even if it does NOT match the list of tags passwd to --tags option
  - only exception: when it is explicitly skipped
    - using '--skip-tags always' option
- 'never'
  - a resource tagged 'never' does not run
  - unless playbook is run with '--tags never'
- 'tagged'
  - runs any resource with an explicit tag
- 'untagged'
  - runs any resource without an explicit tag
  - excludes all tagged resources
- 'all'
  - runs all tasks in play
  - tagged or not
  - is default

Optimizing execution for speed
- in number of ways
  - optimize the infrastructure
  - disable fact gathering
    - gather_facts == ansible.buitling.setup
    - hidden task
    - provides info about nodes
    - use through 'ansible_facts' variable
    - collection info on EACH host takes time
    - replace some gathered variables:
        ansible_facts['hostname'], ansible_hostname, ansible_facts['nodename'], ansible_nodename
        by
        inventory_hostname, inventory_hostname_short magic variables
  - reusing gathered facts with fact caching
    - cache plug-ins store gathered facts or inventory source data
      - gathered by a play
    - fact cache can limit times you need to gather by reusing from cache
    - always enabled
    - can use only one cache plug-ing at a time
    - 'memory' cache is enabled by default
    - in multi play playbooks
      - a first play can gather facts for [all] hosts
      - subsequent play can use the facts
      - and disable gather_facts for themselves
    - use 'smart gathering'
      - in ansible.cfg
      - gathering=smart
      - gathers facts for each NEW host in aplybook run
        - if host used across multiple play
        - NOT contacted again in the run
  - fact caching works by default on automation controller
    - you can select 'Enable Fact Storage' in job template
      - changes caching plug-in
      - to one that stores facts gathered by jobs launched by template
      - facts can be reuse between multiple playbook runs
    - default plugin is 'memory'
      - only cache facts furing a particular job run

Limit Fact gathering
- disable fact gathering at play level
- use ansible.builtin.setup module as explicit task
- with its 'gather_subset' options:
  - all | min | hardware | network | virtual | ohai | facter
  - eg. '!network' to exclude the network facts
- generally quicker than gathering at play level

Increasing parallelism
- ansible runs first task on every host in current batch [of hosts]
- the runs second task etc. until play completes
- 'forks' parameter controls active connection at the same time [parallelism]
- default is 5
  - jobs are processed in groups of five hosts at a time
- increasing the 'forks' allow for mote task simultaneously
  - playbook may complete in less time
  - place more load on control node
- set 'forks' in ansible.cfg
  forks=100
- or on CLI -f option with ansible-navigator

Avoid looping with Package Manager modules
- some modules accept a list of items to work on
  - do not require a loop
  - eg. ansible.builtin.yum
- increases efficiency
  - job with list is called only one time
  - job with loop is called for every item in the loop
  - eg. package managers [yum/dnf]
    - list: calls yum/dnf once for all packages
    - loop: calls yum/dnf once for EVERY package
- other do NOT accept a list
  - eg. ansible-builtin.service
  - loop is needed for multiple services

Efficiently copying files to managed hosts
- use ansible.builtin.copy:
  - on multiple runs, subsequent runs take less time
    - only files that are different are copied
- more efficient to use ansible.posix.synchronize
  - uses 'rsync' in the background
  - usually faster than copy
  - use option 'delete: true' can also remove file on target that no longer exist in source

Using Templates
- using eg. ansible.builtin.lineinfile: is inefficient with a loop
  - and can als be error-prone
  - eg whith several/alotof 'regexp;' options
- use ansible.builtin.template: instead
  - use a <name>.j2 templatefile as the src:

Enable Pipelining
- Ansible performs several SSH operation to run a task on a remote node
- use pipelining feature to increase performance
  - ansible establishes fewer SSH connections
- set ANSIBLE_PIPELINING environment variable
  - true or false
  - in execution environment
  - default NOT used
  - requires the 'requiretty sudo' option on all remote nodes disabled
  - that sudo option by default already DISABLED on RHEL8
    - may impair other platforms

Profiling Playbook Execution with Callback Plug-ins
- callback plug-ins extend Ansible
  - by adjusting how it responds to various events
- some plug-ins modify the output of the cli tools
  - such as 'ansible-navigator'
- eg. 'timer' plugin
  - shows playbook execution time
  - in output of ansible-navigator
- ansible-controller logs some information about jobs
  - extracted from ansible-navigator output
  - so use callback plug-ins with caution
- specified in ansible.cfg
  - callback_enabled=time, profile_tasks, cgroup_perf_recap
- use ansible-navigator to list available callback plug-ins
  - $ ansible-navigator doc -t callback -l -m stdout
  - $ ansible-navigator doc -t callback timer -m stdout

Timing tasks and roles
- to help identify slow tasks and roles
  - 'timer'
    - display duration of playbook execution
  - 'profile_tasks'
    - display start time of each task
    - time spent on each task
    - sorted in descneding order
    - at end of palybook execution
  - 'profile_roles'
    - time psent on each roel at end of the output
    - sorted in descending order
- update 'callbacks_enabled' in ansible.cfg to activate
